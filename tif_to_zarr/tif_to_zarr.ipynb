{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "import xarray as xr\n",
    "import dask\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import os \n",
    "import logging\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "import stat\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def attributes_update(dataset, title, resolution, zip_url):\n",
    "        latitudeattrs = {'_CoordinateAxisType': 'Lat', \n",
    "                            'axis': 'Y', \n",
    "                            'long_name': 'latitude', \n",
    "                            'max': dataset.latitude.values.max(), \n",
    "                            'min': dataset.latitude.values.min(), \n",
    "                            'standard_name': 'latitude', \n",
    "                            'step': (dataset.latitude.values.max() - dataset.latitude.values.min()) / dataset.latitude.values.shape[0], \n",
    "                            'units': 'degrees_north'\n",
    "            }\n",
    "        longitudeattrs = {'_CoordinateAxisType': 'Lon', \n",
    "                        'axis': 'X', \n",
    "                        'long_name': 'longitude',\n",
    "                        'max': dataset.longitude.values.max(),\n",
    "                        'min': dataset.longitude.values.min(),\n",
    "                        'standard_name': 'longitude', \n",
    "                        'step': (dataset.longitude.values.max() - dataset.longitude.values.min()) / dataset.longitude.values.shape[0], \n",
    "                        'units': 'degrees_east'\n",
    "        }\n",
    "        dataset.latitude.attrs.update(latitudeattrs)\n",
    "        dataset.longitude.attrs.update(longitudeattrs)\n",
    "\n",
    "        # Set the CRS as an attribute\n",
    "        dataset.attrs['proj:epsg'] = 4326\n",
    "        dataset.attrs['resolution'] = resolution\n",
    "        dataset.attrs.update({\n",
    "            'geospatial_lat_min': dataset['latitude'].min().item(),\n",
    "            'geospatial_lat_max': dataset['latitude'].max().item(),\n",
    "            'geospatial_lon_min': dataset['longitude'].min().item(),\n",
    "            'geospatial_lon_max': dataset['longitude'].max().item()\n",
    "        })\n",
    "        dataset.attrs['history'] = f'Converted on {date.today()}'\n",
    "        dataset.attrs['title'] = title\n",
    "      \n",
    "        dataset.attrs['Comment'] = f\"Downloaded from {zip_url} Converted from data product {title}.tif on {datetime.today()}\"\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download zipfile containing geotiff for conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_zip(zip_url, target_tif_file):\n",
    "    zip_file_path = '/zipfiles/temp.zip'\n",
    "    # Download the zip file\n",
    "    response = requests.get(zip_url)\n",
    "    with open(zip_file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    # Extract the contents of the zip file\n",
    "    with ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall('/zipfiles')\n",
    "    # Find the .shp file\n",
    "    tif_file_path = None\n",
    "    for root, dirs, files in os.walk('/zipfiles'):\n",
    "        \n",
    "        for file in files:\n",
    "            if file.endswith(\".tif\") and os.path.basename(file) == target_tif_file:\n",
    "                tif_file_path = os.path.join(root, file)\n",
    "                break\n",
    "    return tif_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert geotiff to xarray dataset and save to zarr\n",
    "\n",
    "Choose your own chunk size depending on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tif2zarr(file_path, variable, arco_asset_temp_dir, zip_url):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        band_count = src.count\n",
    "        band_descriptions = src.descriptions\n",
    "    \n",
    "    # Choose a different size if the file is too large\n",
    "    chunk_size = 'auto'\n",
    "    \n",
    "    # Extract the title without the .tif extension\n",
    "    title = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    # Open the file in chunks\n",
    "    da = rxr.open_rasterio(file_path, chunks=chunk_size)\n",
    "    # Assign a name to the DataArray\n",
    "    da.name = variable\n",
    "    # Convert the DataArray to a Dataset\n",
    "    ds = da.to_dataset()\n",
    "    # Rename the 'band' dimension to 'kdpar'\n",
    "    ds = ds.rename({ 'x': 'longitude', 'y': 'latitude'})\n",
    "    # Rechunk the data\n",
    "    # Sort by latitude\n",
    "    ds = ds.sortby('latitude')\n",
    "\n",
    "    ds = ds.chunk({'latitude': chunk_size, 'longitude': chunk_size})\n",
    "    ds[variable]= ds[variable].chunk({'latitude' : chunk_size, 'longitude': chunk_size})\n",
    "    # Get the band number and variable names\n",
    "    variable_names = list(ds.data_vars)\n",
    "    resolution = abs(ds.latitude.values[0] - ds.latitude.values[1])\n",
    "    # Add attributes to the dataset\n",
    "    ds.attrs['band_count'] = band_count\n",
    "    ds.attrs['band_descriptions'] = band_descriptions\n",
    "    ds.attrs['variables'] = variable_names\n",
    "    ds = attributes_update(ds, title, resolution, zip_url)\n",
    "    zarr_path = f'{arco_asset_temp_dir}/{variable}.zarr'\n",
    "    with dask.config.set(scheduler='threads'):  # use the threaded scheduler\n",
    "        ds.to_zarr(zarr_path, mode='w')\n",
    "    return zarr_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide inputs\n",
    "\n",
    "Provide the zipurl to be downloaded, the geotiff to be converted, and the name of the variable of the geotiff raster (ex secchi disk water depth ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # if len(sys.argv) != 3:\n",
    "    #     print('Usage: python tif_to_zarr.py <zip_url> <band_variable>')\n",
    "    #     sys.exit(1)\n",
    "    # zip_url = sys.argv[1]\n",
    "    # variable = sys.argv[2]\n",
    "    # arco_asset_temp_dir = os.environ.get('ARCO_ASSET_TEMP_DIR')\n",
    "\n",
    "    # defaults for testing\n",
    "    zipdir = 'zipfiles'\n",
    "    os.makedirs(zipdir, exist_ok=True)\n",
    "    zip_url = \"https://s3.waw3-1.cloudferro.com/emodnet/emodnet_native/emodnet_seabed_habitats/environmental_variables_that_influence_habitat_type_optical_properties/ratio_of_depth_to_seabed_secchi_disk_depth_in_baltic_sea/baltic_secchi_disk_depth_ratio.zip\"\n",
    "    tif_file = 'baltic_secchi_disk_depth_ratio.tif'\n",
    "    \n",
    "    variable = \"secchi_disk_water_depth_ratio\"\n",
    "    arco_asset_temp_dir = 'data'\n",
    "    zipdir = 'zipfiles'\n",
    "    os.makedirs(zipdir, exist_ok=True)\n",
    "\n",
    "    tif_file_path = download_and_extract_zip(zip_url)\n",
    "    print(tif_file_path)\n",
    "    permissions = stat.filemode(os.stat(tif_file_path).st_mode)\n",
    "    if tif_file_path:\n",
    "        metadata_dict = {}  # Add your metadata here\n",
    "        zarr_path = tif2zarr(tif_file_path, variable, arco_asset_temp_dir, zip_url)\n",
    "        print(f'Zarr file saved at {zarr_path}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
